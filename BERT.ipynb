{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5BHc+cVshAIk3Z6ww+fp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barthwalsamarth/DLCourse-Andrew-Ng/blob/master/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9xGHHU_GUnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8789aae-0301-46f7-b73b-6023659ee51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "# installing hugging face library\n",
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting all the imports\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch"
      ],
      "metadata": {
        "id": "6-HVuympGa7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading all the data\n",
        "\n",
        "trainpath = '/home/data/train_data.xlsx'\n",
        "testpath = '/home/data/test_data.xlsx'\n",
        "\n",
        "traindf = pd.read_excel(trainpath)\n",
        "testdf = pd.read_excel(testpath)"
      ],
      "metadata": {
        "id": "XyfIpEnAKcLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT tokeninzer\n",
        "from transformers import BertTokenizer\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cymM7agMGz_",
        "outputId": "0c9ab115-95c0-4615-f108-a2c0c8f9f381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('original sentence :', traindf.iloc[51]['text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OobSA7OOMRzU",
        "outputId": "fb03aa53-7dd3-480c-d2c1-d9b83776ca31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original sentence : Keywords (1993)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenized :', tokenizer.tokenize(traindf.iloc[51]['text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlpl-DdqMqyy",
        "outputId": "d2a7430e-9f44-4d24-dd9d-8cd2ab2aff8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized : ['key', '##words', '(', '1993', ')']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(traindf.iloc[51]['text'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebzIcR80wukD",
        "outputId": "10fc39ef-4d27-4c40-a7ba-d84e04215a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:  [3145, 22104, 1006, 2857, 1007]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the TRAIN sentences and map the tokens to thier word IDs.\n",
        "\n",
        "sentences_train = traindf['text'].to_list()\n",
        "len_sentences_train = [len(str(a)) for a in sentences_train]\n",
        "print('longenst sentence with length = ', np.max(len_sentences_train))\n",
        "\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# For every sentence...\n",
        "for ix,sent in enumerate(sentences_train):\n",
        "\n",
        "  # `encode_plus` will:\n",
        "  #   (1) Tokenize the sentence.\n",
        "  #   (2) Prepend the `[CLS]` token to the start.\n",
        "  #   (3) Append the `[SEP]` token to the end.\n",
        "  #   (4) Map tokens to their IDs.\n",
        "  #   (5) Pad or truncate the sentence to `max_length`\n",
        "  #   (6) Create attention masks for [PAD] tokens.\n",
        "  encoded_dict_train = tokenizer.encode_plus(\n",
        "                      sent,                      # Sentence to encode.\n",
        "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                      max_length = 300,          # Pad & truncate all sentences.\n",
        "                      pad_to_max_length = True,\n",
        "                      return_attention_mask = True,   # Construct attn. masks.\n",
        "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                  )\n",
        "  \n",
        "  # Add the encoded sentence to the list.    \n",
        "  input_ids_train.append(encoded_dict_train['input_ids'])\n",
        "  \n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_masks_train.append(encoded_dict_train['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "labels_train = torch.tensor(traindf['truth'].to_list())\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "#print('Original: ', sentences[0])\n",
        "#print('Token IDs:', input_ids[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lBiVmTvx-S2",
        "outputId": "c8f8a98e-aa6d-433e-dd23-78dafb641c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "longenst sentence with length =  706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the TEST sentences and map the tokens to thier word IDs.\n",
        "\n",
        "sentences_test = testdf['text'].to_list()\n",
        "len_sentences_test = [len(str(a)) for a in sentences_test]\n",
        "print('longenst sentence with length = ', np.max(len_sentences_test))\n",
        "\n",
        "input_ids_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "# For every sentence...\n",
        "for ix,sent in enumerate(sentences_test):\n",
        "\n",
        "  # `encode_plus` will:\n",
        "  #   (1) Tokenize the sentence.\n",
        "  #   (2) Prepend the `[CLS]` token to the start.\n",
        "  #   (3) Append the `[SEP]` token to the end.\n",
        "  #   (4) Map tokens to their IDs.\n",
        "  #   (5) Pad or truncate the sentence to `max_length`\n",
        "  #   (6) Create attention masks for [PAD] tokens.\n",
        "  encoded_dict_test = tokenizer.encode_plus(\n",
        "                      sent,                      # Sentence to encode.\n",
        "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                      max_length = 300,           # Pad & truncate all sentences.\n",
        "                      pad_to_max_length = True,\n",
        "                      return_attention_mask = True,   # Construct attn. masks.\n",
        "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                  )\n",
        "  \n",
        "  # Add the encoded sentence to the list.    \n",
        "  input_ids_test.append(encoded_dict_test['input_ids'])\n",
        "  \n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_masks_test.append(encoded_dict_test['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "labels_test = torch.tensor(testdf['truth'].to_list())\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "#print('Original: ', sentences[0])\n",
        "#print('Token IDs:', input_ids[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FyVFy7Ryizx",
        "outputId": "f17a015b-33ee-46be-ddea-94cbc65094dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "longenst sentence with length =  711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_train.shape, input_ids_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4cL19vpy07g",
        "outputId": "57fba884-10d8-428b-fa19-af55b709b2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([7259, 300]), torch.Size([2270, 300]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks_train.shape, attention_masks_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afNVp-MF2BXn",
        "outputId": "5f438d67-0952-4a96-9472-cfdc84143f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([7259, 300]), torch.Size([2270, 300]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train.shape, labels_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4XmBNqA9PP9",
        "outputId": "252716b6-bbd3-4a3c-97f0-1e496550f0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([7259]), torch.Size([2270]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKSnhcNL9RgF",
        "outputId": "ce867847-4659-4922-c4b9-294ab424f0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6,533 training samples\n",
            "  726 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "metadata": {
        "id": "Zw_M7cOG-BX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IQU8rCBpSPM",
        "outputId": "106d0bde-7c91-4484-e839-5311957872cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m6XO-PXwNFF",
        "outputId": "5f4647e5-1b87-4d78-e220-b9688b8f9c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "metadata": {
        "id": "7c56IRTUq24D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "ZGz2cRyBrBXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "dBOGrOVsrKQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i-xIqDMrlNi",
        "outputId": "b498b90c-90bd-41d8-ac6a-bd0d09dd3864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "\n",
        "  # ========================================\n",
        "  #               Training\n",
        "  # ========================================\n",
        "    \n",
        "  # Perform one full pass over the training set.\n",
        "\n",
        "  print(\"\")\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  print('Training...')\n",
        "\n",
        "  # Measure how long the training epoch takes.\n",
        "  t0 = time.time()\n",
        "\n",
        "  # Reset the total loss for this epoch.\n",
        "  total_train_loss = 0\n",
        "\n",
        "  # Put the model into training mode. Don't be mislead--the call to \n",
        "  # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "  # `dropout` and `batchnorm` layers behave differently during training\n",
        "  # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "  model.train()\n",
        "\n",
        "  # For each batch of training data...\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "        # Calculate elapsed time in minutes.\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        # Report progress.\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "    # `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. PyTorch doesn't do this automatically because \n",
        "    # accumulating the gradients is \"convenient while training RNNs\". \n",
        "    # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "    model.zero_grad()        \n",
        "\n",
        "    # Perform a forward pass (evaluate the model on this training batch).\n",
        "    # The documentation for this `model` function is here: \n",
        "    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "    # It returns different numbers of parameters depending on what arguments\n",
        "    # arge given and what flags are set. For our useage here, it returns\n",
        "    # the loss (because we provided labels) and the \"logits\"--the model\n",
        "    # outputs prior to activation.\n",
        "    output = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "\n",
        "    loss = output.loss\n",
        "    logits = output.logits\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can\n",
        "    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "    # single value; the `.item()` function just returns the Python value \n",
        "    # from the tensor.\n",
        "    total_train_loss += loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the norm of the gradients to 1.0.\n",
        "    # This is to help prevent the \"exploding gradients\" problem.\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update the learning rate.\n",
        "    scheduler.step()\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "  \n",
        "  # Measure how long this epoch took.\n",
        "  training_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "      \n",
        "  # ========================================\n",
        "  #               Validation\n",
        "  # ========================================\n",
        "  # After the completion of each training epoch, measure our performance on\n",
        "  # our validation set.\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  # Put the model in evaluation mode--the dropout layers behave differently\n",
        "  # during evaluation.\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "      \n",
        "      # Unpack this training batch from our dataloader. \n",
        "      #\n",
        "      # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "      # the `to` method.\n",
        "      #\n",
        "      # `batch` contains three pytorch tensors:\n",
        "      #   [0]: input ids \n",
        "      #   [1]: attention masks\n",
        "      #   [2]: labels \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "          # Forward pass, calculate logit predictions.\n",
        "          # token_type_ids is the same as the \"segment ids\", which \n",
        "          # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "          # The documentation for this `model` function is here: \n",
        "          # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "          # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "          # values prior to applying an activation function like the softmax.\n",
        "          output = model(b_input_ids, \n",
        "                                  token_type_ids=None, \n",
        "                                  attention_mask=b_input_mask,\n",
        "                                  labels=b_labels)\n",
        "      loss = output.loss\n",
        "      logits = output.logits\n",
        "\n",
        "      # Accumulate the validation loss.\n",
        "      total_eval_loss += loss.item()\n",
        "\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      # Calculate the accuracy for this batch of test sentences, and\n",
        "      # accumulate it over all batches.\n",
        "      total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "      \n",
        "\n",
        "  # Report the final accuracy for this validation run.\n",
        "  avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "  \n",
        "  # Measure how long the validation run took.\n",
        "  validation_time = format_time(time.time() - t0)\n",
        "  \n",
        "  print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "  print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "  # Record all statistics from this epoch.\n",
        "  training_stats.append(\n",
        "      {\n",
        "          'epoch': epoch_i + 1,\n",
        "          'Training Loss': avg_train_loss,\n",
        "          'Valid. Loss': avg_val_loss,\n",
        "          'Valid. Accur.': avg_val_accuracy,\n",
        "          'Training Time': training_time,\n",
        "          'Validation Time': validation_time\n",
        "      }\n",
        "  )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_I47SKZrN7d",
        "outputId": "22eb5cae-1af0-45a5-a9e8-97da979b55d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    409.    Elapsed: 0:00:34.\n",
            "  Batch    80  of    409.    Elapsed: 0:01:08.\n",
            "  Batch   120  of    409.    Elapsed: 0:01:42.\n",
            "  Batch   160  of    409.    Elapsed: 0:02:15.\n",
            "  Batch   200  of    409.    Elapsed: 0:02:49.\n",
            "  Batch   240  of    409.    Elapsed: 0:03:22.\n",
            "  Batch   280  of    409.    Elapsed: 0:03:56.\n",
            "  Batch   320  of    409.    Elapsed: 0:04:29.\n",
            "  Batch   360  of    409.    Elapsed: 0:05:03.\n",
            "  Batch   400  of    409.    Elapsed: 0:05:36.\n",
            "\n",
            "  Average training loss: 0.75\n",
            "  Training epcoh took: 0:05:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    409.    Elapsed: 0:00:33.\n",
            "  Batch    80  of    409.    Elapsed: 0:01:07.\n",
            "  Batch   120  of    409.    Elapsed: 0:01:40.\n",
            "  Batch   160  of    409.    Elapsed: 0:02:14.\n",
            "  Batch   200  of    409.    Elapsed: 0:02:48.\n",
            "  Batch   240  of    409.    Elapsed: 0:03:21.\n",
            "  Batch   280  of    409.    Elapsed: 0:03:55.\n",
            "  Batch   320  of    409.    Elapsed: 0:04:28.\n",
            "  Batch   360  of    409.    Elapsed: 0:05:02.\n",
            "  Batch   400  of    409.    Elapsed: 0:05:35.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:05:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:11:55 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats\n"
      ],
      "metadata": {
        "id": "IJW6E43br2zr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "40031aac-b75f-4ae4-e473-9ad3aaa5c770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.75         0.64           0.78       0:05:43         0:00:15\n",
              "2               0.52         0.59           0.80       0:05:42         0:00:15"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cc75566-dc41-4b0a-b7ca-5cef8973adae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:05:43</td>\n",
              "      <td>0:00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:05:42</td>\n",
              "      <td>0:00:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cc75566-dc41-4b0a-b7ca-5cef8973adae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cc75566-dc41-4b0a-b7ca-5cef8973adae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cc75566-dc41-4b0a-b7ca-5cef8973adae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "yuo4aFLytFFH",
        "outputId": "9f566c9d-c0f0-427a-83cd-233b86ffa27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 32 \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "aaMaHEOzt6q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
        "\n",
        "#move model to gpu\n",
        "model.to(device)\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  #b_labels = batch[2].to(device)\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ],
      "metadata": {
        "id": "EOPzKAxIuP6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e91a60-f16e-488a-a888-d5e38347892e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 2,270 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(logits)"
      ],
      "metadata": {
        "id": "xdYKRhcNu9aK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "0175ee3e-078b-451b-8a7c-efae9c960fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8877009afcb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  print(np.shape(true_labels[i]))\n",
        "  print(np.shape(pred_labels_i))\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Iy7XnF8e4owg",
        "outputId": "fefcace1-f94f-4120-c253-fe5f0a25cdeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "(6,)\n",
            "(32,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-bd66cc3b2d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Calculate and store the coef for this batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mmatthews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mmatthews_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatthews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mmatthews_corrcoef\u001b[0;34m(y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6, 32]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eDweaXuZ4pVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)\n"
      ],
      "metadata": {
        "id": "vuzbFdOp4pqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_labels_list = []\n",
        "true_labels_list = []\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  temp_pred = list(np.argmax(predictions[i], axis=1).flatten())\n",
        "  temp_true = list(true_labels[i])  \n",
        "  for i in temp_pred: pred_labels_list.append(i)\n",
        "  for j in temp_true: true_labels_list.append(i)"
      ],
      "metadata": {
        "id": "V4N93yUv4p9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnfmx = confusion_matrix(true_labels_list, pred_labels_list)"
      ],
      "metadata": {
        "id": "FDgX6bs04qRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnfmx"
      ],
      "metadata": {
        "id": "d9GgDPIf7nkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAiezIju7n68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2nv426q7oU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from numba import cuda\n",
        "cuda.select_device(0)\n",
        "cuda.close()\n",
        "\n",
        "#gc.collect() # python gc\n",
        "'''"
      ],
      "metadata": {
        "id": "lIsXCh-44gqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "DrK8DQewEVaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "t_AfIHRDIW4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dPSk2hCQKKOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}